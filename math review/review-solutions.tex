\documentclass[10pt]{article}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{graphicx}
%\usepackage{epstopdf}
\usepackage{hyperref}
\usepackage[left=.9in,right=.9in,top=.7in,bottom=.7in]{geometry}
\usepackage{multirow}
\usepackage{verbatim}
\usepackage{fancyhdr}

%\usepackage{pxfonts}
%\usepackage{isomath}
\usepackage{mathpazo}
%\usepackage{arev} %     (Arev/Vera Sans)
%\usepackage{eulervm} %_   (Euler Math)
%\usepackage{fixmath} %  (Computer Modern)
%\usepackage{hvmath} %_   (HV-Math/Helvetica)
%\usepackage{tmmath} %_   (TM-Math/Times)
%\usepackage{cmbright}
%\usepackage{ccfonts} \usepackage[T1]{fontenc}
%\usepackage[garamond]{mathdesign}
\usepackage{color}
\usepackage{ulem}
%\usepackage{setspace}
%\onehalfspacing

\newcommand{\argmax}{\operatornamewithlimits{arg\,max}}
\newcommand{\argmin}{\operatornamewithlimits{arg\,min}}
\newcommand{\myTable}[1]{\begin{table}[b]\caption{#1}
    \begin{minipage}{\linewidth} \begin{center}}
\newcommand{\myTableEnd}{\end{center}\end{minipage}\end{table}}

\def\inprobLOW{\rightarrow_p}
\def\inprobHIGH{\,{\buildrel p \over \rightarrow}\,} 
\def\inprob{\,{\inprobHIGH}\,} 
\def\indist{\,{\buildrel d \over \rightarrow}\,} 

\newtheorem{theorem}{Theorem}

%\pagestyle{fancy}
\renewcommand{\sectionmark}[1]{\markright{#1}{}}
 
%\fancyhead[LE,LO]{\thepage}
%\fancyhead[CE,CO]{\rightmark}
%\fancyfoot[C]{}

\title{Solutions to review exercises}
\date{}
\begin{document}
\maketitle

\section{An Introduction to Logic and Proofs}

\subsection{Logic}
\newcounter{savedcount}
\renewcommand{\labelenumi}{\textbf{Exercise \arabic{enumi}}}
\renewcommand{\labelenumii}{\roman{enumii}}
\begin{enumerate}
\item \textit{For each of the following sentence, state whether it is an atomic
proposition or a compound proposition or neither.}
\begin{enumerate}
\item \textit{Today is a hot day} \\
  atomic
\item \textit{$9+8-7=44$} \\
  atomic
\item \textit{$y = 6x$ or $x = (1/6)y$} \\
  neither
\item \textit{Is it too loud or too quiet
    in here?} \\
  neither
\end{enumerate}
\item \textit{Exercise 2 Suppose $P$, $R$, and $S$ are atomic propositions. Construct the
truth tables for the propositional form;} 
\begin{enumerate}
  \item $(P \wedge R) \vee S$
    \[ \left\vert\begin{array}{cccc} 
        P & R & S & (P \wedge R) \vee S \\
        T & T & T & T \\
        T & T & F & T \\
        T & F & T & T \\
        F & T & T & T \\
        F & F & T & T \\
        F & T & F & F \\
        T & F & F & F \\
        F & F & F & F
      \end{array}
    \right\vert \]      
  \item $P \wedge R \wedge S$ 
    \[ \left\vert\begin{array}{cccc} 
        P & R & S & P \wedge R \wedge S \\
        T & T & T & T \\
        T & T & F & F \\
        T & F & T & F \\
        F & T & T & F \\
        F & F & T & F \\
        F & T & F & F \\
        T & F & F & F \\
        F & F & F & F
      \end{array}
    \right\vert \]
  \item $P \vee R \vee S$
    \[ \left\vert\begin{array}{cccc} 
        P & R & S & P \vee R \vee S \\
        T & T & T & T \\
        T & T & F & T \\
        T & F & T & T \\
        F & T & T & T \\
        F & F & T & T \\
        F & T & F & T \\
        T & F & F & T \\
        F & F & F & F
      \end{array}
    \right\vert \]
  \end{enumerate}
\item \textit{Suppose $P$ and $R$ are atomic propositions. Show using truth
    tables that the functional form $P \vee (R \wedge P)$ is
    equivalent to $P$.}
  \[ \left\vert\begin{array}{ccc} 
      R & P & P \vee (R \wedge P) \\
      T & T & T \\
      F & T & T \\
      T & F & F \\
      F & F & F 
    \end{array} \right\vert \]
\item \textit{Suppose $P$ and $R$ are atomic propositions. Are the following
    propositional forms a tautology, a contradiction or neither?}
  \begin{enumerate}
  \item $P\wedge \sim (R\vee P)$
    Contradiction. 
  \item $(P \wedge R) \vee (\sim P\wedge \sim R)$
    Neither, $T$ if $P$ and $R$ are both $T$ or both $F$, else $F$
  \item $P \wedge (\sim R \wedge \sim P)$
    Contradiction. 
  \end{enumerate}
\item \textit{Suppose $P$ and $R$ are two atomic propositions. Show that
    $P \Rightarrow R$ is equivalent to $(\sim P) \vee R$.} \\
  Suppose $(\sim P) \vee R$ is true. If $P$ is true, then $(\sim P)$
  is false, and $R$ must be true for $(\sim P) \vee R$ to
  hold. Conversely, suppose $P \Rightarrow R$. If $P$ is false, then
  $\sim P$ is true, so $(\sim P) \vee R$ is true. If $P$ is true, $R$
  is true, so $(\sim P) \vee R$ is true. 
\item \textit{Suppose $P$ and $R$ are two atomic propositions. Show that $P \Rightarrow
R$ is equivalent to its contrapositive and that $P \Rightarrow R$ is not equivalent to
its converse. For the latter, illustrate with an example using a language by
choosing $P$ and $R$ such that $P \Rightarrow R$ is true and its
converse is not.} \\
From the previous exercise, $P \Rightarrow R$ is equivalent to $(\sim
P) \vee R$, which is equivalent to $(\sim(\sim R)) \vee (\sim P)$
since $\sim (\sim R)$ is equivalent to $R$ and $A \vee B$ is eqivalent
to $B \vee A$. Then, from the previous exercise again, $(\sim(\sim R))
\vee (\sim P)$ is equivalent to $\sim R \Rightarrow \sim P$.  \\
If you can see the sun, then it is daytime, but if you can't see the
sun, it need not be not daytime. It could be cloudy.
\item \textit{Prove Theorem 1.}
  Like the footnote says, this is tedious. You could draw truth tables
  for all of these. 
\item \textit{Assume the universe is the set of real numbers $\mathbb{R}$. Are the fol-
    lowing propositions true?} 
  \begin{enumerate}
  \item $ \forall x, x + 2 ≥ 0$ \\
    False.
  \item $\exists x \sqrt{x} = −8$ \\
    False.
  \item $\forall x, 2 + 2 = x$\\
    False. 
  \end{enumerate}
\item \textit{Assume the universe is the set of real numbers $\mathbb{R}$. Show that the
    following is true. $\forall x, \exists y, \sqrt{(x − 1)^2 − (y + 2)^2} = 0$.}
  Let $y=x-3$. It is hard to say how much more one should do since we
  haven't rigorously defined $\mathbb{R}$.  A really careful answer
  would verify that this $y$ is in $\mathbb{R}$ and that the
  expression, $\sqrt{(x − 1)^2 − (y + 2)^2}$ is always well-defined.  
  $y$ is contained in $\mathbb{R}$ because $x \in
  \mathbb{R}$, $3 \in \mathbb{R}$, and $\mathbb{R}$ is closed under
  addition (since it's a field).  Similarly, $(x-1)^2$ and $(y+2)^2$
  are in $\mathbb{R}$ since $\mathbb{R}$ is closed under
  multiplication. Finally, when $y=x-3$, $(x-1)^2 - (y+2)^2 = 0$, so
  the square root is well-defined and equal to zero.  
  \setcounter{savedcount}{\value{enumi}}
\end{enumerate}

\subsection{Proofs}

\begin{enumerate}
  \setcounter{enumi}{\value{savedcount}}
\item \textit{Suppose $a$ is an integer. Prove that if $a^2$ is odd then
    $a$ is odd.} \\
  Proving the contrapositive is really easy given example 6. If $a$ is
  even, then by example 6, $a \times a = a^2$ is even. Hence, if $a^2$
  is not even, $a$ is not even.
\item \textit{Suppose $a$ and $b$ are integers. Prove that if $a$ and
    $b$ are even, then $a + b$ is even.} \\
  If $a$ and $b$ are even, then $\exists$ integers, $\tilde{a}$ and
  $\tilde{b}$ such that $2 \tilde{a} = a$ and $2 \tilde{b} = b$. Then, 
  \begin{align*}
    a + b = & 2\tilde{a} + 2 \tilde{b} \\
    = & 2 (\tilde{a} + \tilde{b})
  \end{align*}
  is even.
\item \textit{Prove that there exists integers $a$ and $b$ such that $3a−4b =
    73$.} \\
  Any example suffices, e.g.\ $b = 2$, $a = 27$.
\item\textit{Prove that there exists an odd integer $a$ and an even integer $b$
    such that $3a + 4b = 17$.} \\
  Again any example suffices. To come up with one, it may help to 
  observe that this is equivalent to finding an integer solution to
  $3(2x+1) + 4(2y) = 17$. One solution is $a = -5$, $b=8$.
\item \textit{Prove that for all $n \in \mathbb{N}$, $2n \geq 1 + n$.} \\
  By induction. For $n=1$, $2 = 2$. Suppose $2(n-1) \geq 1 + (n-1)$,
  then $2n \geq n + 2 > n + 1$. 
\item \textit{Is the following true or false? If true, prove. If false, show a
    counterexample. For all $n \in \mathbb{N}$, $n^2 + 1 < n^3$}. \\
  It is false for $n=1$. 
\end{enumerate}

\section{Elementary Calculus}
\renewcommand{\labelenumi}{\arabic{enumi}}
\begin{enumerate}
\item \textit{Adapt the above methodology to obtain formulae for the
    derivatives $\partial d(p, w, \alpha)/\partial w$, $\partial d(p, w, \alpha)/\partial \alpha$,
    $\partial s(p, w, \alpha)/\partial w$ and $\partial s(p, w, \alpha)/\partial \alpha$.  Sign these
    derivatives.}\\
  As in p17, equation (9), the producer's first order condition is 
  \[ p\alpha f'(x^*) - w = 0 \]
  Combining this with the equilibrium condition, $x^* =
  d(p,w,\alpha)$, we have
  \[ p \alpha f'(d(p,w,\alpha)) - w = 0 \]
  Differentiating with respect to w, 
  \begin{align*}
    p \alpha f''\left(d(p,w,\alpha)\right) \frac{\partial d}{\partial
      w}(p,w,\alpha) = & 1\\
    \frac{\partial d}{\partial
      w}(p,w,\alpha) = & \frac{1}{p\alpha f''
      \left(d(p,w,\alpha)\right)}
  \end{align*}
  We know from the second condition that $p\alpha f''(d(p,w,\alpha)) <
  0$, so $\frac{\partial d}{\partial w}(p,w,\alpha) < 0$. As input the
  price increases, input demand decreases. 

  Repeating the same steps, but differentiating by $\alpha$ instead,
  yields
  \begin{align*}
    p \alpha f'\left(d(p,w,\alpha)\right) -w = & 0  \\
    p f'\left(d(p,w,\alpha)\right) + p \alpha f''\left(d(p,w,\alpha)\right) \frac{\partial d} {\partial
      \alpha} (p,w,\alpha) = & 0 \\
    \frac{\partial d} {\partial
      \alpha} (p,w,\alpha)  = & -\frac{f'\left(d(p,w,\alpha)\right)} {\alpha
      f''\left(d(p,w,\alpha)\right) } .
  \end{align*}
  $f'$ is positive and $f''$ is negative, so $\frac{\partial d} {\partial
    \alpha} $ is positive. As efficiency increases, input demand
  increases. 
  
  To determine the sign of $\frac{\partial s} {\partial w}$, we can
  follow the same steps as on p18. 
  \begin{align*}
    s(p,w,\alpha) = & \alpha f(d(p,w,\alpha)) \\
    \frac{\partial s}{\partial w} = & \alpha
    \underbrace{f'\left(d(p,w,\alpha)\right)}_{(+)} 
    \underbrace{\frac{\partial d}{\partial w}}_{(-)} \\
    < & 0
  \end{align*}
  Thus, as the input price increases, supply decreases. 

  Similarly, for $\frac{\partial s}{\partial \alpha}$,
  \begin{align*}
    \frac{\partial s}{\partial \alpha} = & \underbrace{f(d(p,w,\alpha))}_{(+)} + \alpha
    \underbrace{f'(d(p,w,\alpha))}_{(+)} \underbrace{\frac{\partial
        d}{\partial \alpha} }_{(+)} \\
    > & 0.
  \end{align*}

\item \textit{Show that $\partial \pi(p, w, \alpha)/\partial w = -d(p, w, \alpha)$
    (Hotelling's Lemma).}\\
  Begin by writing the profit function in terms of input demand,
  \begin{align*}
    \pi(p,w,\alpha) = p \alpha f(d(p,w,\alpha)) - w d(p,w,\alpha).
  \end{align*}
  Differentiate with respect to $w$,
  \begin{align*}
    \frac{\partial \pi} {\partial w} = & p \alpha f'(d(p,w,\alpha))
    \frac{\partial d}{\partial w} - w \frac{\partial d}{\partial w} -
    d(p,w,\alpha) \\
    = & \frac{\partial d}{\partial w} \underbrace{\left(p \alpha
        f'(d(p,w,\alpha)) - w \right)}_{=0 \mathrm(first order condition)} - d(p,w,\alpha) \\
    = & -d(p,w,\alpha).
  \end{align*}
\item\textit{Show  that  $\partial s(p, w,  a)\alpha f'(d(p,w,\alpha))/\partial w  =  -\partial
    d(p, w,  a)/\partial p$  (Hotelling  Symmetry Condition).}  
  As in equation 12, 
  \begin{align*}
    0 = & p \alpha f'(d(p,w,\alpha)) - w \\
    = & \alpha f' + p\alpha f'' \frac{\partial d}{\partial p} \\
    \frac{\partial d}{\partial p} = & -\frac{f'}{p f''}.
  \end{align*}
  As in question 1, 
  \begin{align*}
    s(p,w,\alpha) = & \alpha f(d(p,w,\alpha)) \\
    \frac{\partial s}{\partial w} = & \alpha f' \frac{\partial
      d}{\partial w},
  \end{align*}
  and
  \begin{align*}
    \frac{\partial d}{\partial w} = \frac{1}{p \alpha f''}.
  \end{align*}
  Substituting into the previous equation gives, 
  \[ \frac{\partial s}{\partial w} = \frac{f' }{p f''}. \]
  Thus, 
  \[ \frac{\partial s}{\partial w} = -\frac{\partial d}{\partial p} \]
  
\item \textit{Calculate the consumer's system of demand functions
    $D_1(p_1, p_2, I)$ and $D_2 (p_1, p_2, I)$ if the consumer's
    utility function is defined by:}
    \[  u(x1, x2) ≡ f[x_1^{1/2} x_2^{1/2} ], \]  
    \textit{where $f$ is a continuously differentiable function of one
    variable which has $f'(x) > 0$ for all $x > 0$.}
  The consumer's optimization problem is 
  \begin{align*}
    \max_{x_1,x_2} f[x_1^{1/2} x_2^{1/2} ] \text{ s.t. } p_1 x_1 + p_2
    x_2 \leq I
  \end{align*}
  One approach would be write the Lagrangian and solve from
  there. This actually leads to simpler algebra. Another way to
  proceed is to simplify this to a single dimensional maximization
  problem by substituting in the constraint. This gives
  \begin{align*}
    \max_{x_1} f\left[x_1^{1/2} \left(\frac{I - p_1 x_1}{p_2}\right)^{1/2}\right]
  \end{align*}
  The first order condition is
  \begin{align*}
    0 = & f'\left[x_1^{1/2} \left(\frac{I - p_1 x_1}{p_2}\right)^{1/2}\right] 
    \frac{1}{2}\left(\left(\frac{I - p_1 x_1}{x_1 p_2}\right)^{1/2} +
    \left(\frac{p_2}{x_1}{I - p_1 x_1}\right)^{1/2} \frac{-p_1}{p_2}\right) \\
    = & \left( (I-p_1 x_1) + p_2 x_1 \frac{-p_1}{p_2}\right) \\
    x_1 = & I/(2 p_1) 
  \end{align*}
  and $x_2 = I/(2 p_2)$. To verify that this is indeed a maximum, we
  should check the second order condition as well,
  \begin{align*}
    f''\left[x_1^{1/2} \left(\frac{I - p_1 x_1}{p_2}\right)^{1/2}\right]
    \underbrace{\frac{1}{2}\left(\left(\frac{I - p_1 x_1}{x_1
            p_2}\right)^{1/2} + 
    \left(\frac{p_2}{x_1}{I - p_1 x_1}\right)^{1/2}
    \frac{-p_1}{p_2}\right)}_{ = 0 
  \text{(first order condtion)}}
+ \frac{1}{2} f'\left[x_1^{1/2} \left(\frac{I - p_1
      x_1}{p_2}\right)^{1/2}\right] 
\left(\text{tedious to type, but is negative} \right) < 0
  \end{align*}
\item \textit{Solve $max_x {f(x):  x ≥ 0}$ for the following functions
    $f$:}
    \begin{itemize}
    \item[(a)] $f(x) = -x^2 + 2x - 2$
    \item[(b)] $f(x) = \ln x - x + 1$
    \item[(c)] $f(x) = -x^2 - 2x$.
    \end{itemize}
    \textit{Check the relevant second order condition.} 
\item \textit{Solve $max_{x_1, x_2} f(x1, x2)$ for the following $f$:}
    \begin{itemize}
    \item[(a)]  $f(x_1, x_2) = -x_1^2 + x_1 x_2 - x_2^2 + 2$
    \item[(b)] $f(x_1, x_2) = \ln x_1 + \ln x_2 - 2x_1 - 2x_2 + 2$
    \end{itemize}
    \textit{Check the relevant second order conditions.}
  \item \textit{(From p32 of part 3) Problem: Determine whether the
      following functions have any local minimums or maximums.  Check
      the relevant second order conditions.  The domain of definition
      for each function is two dimensional space. }
  \begin{itemize}
  \item[(i)]  $f(x_1,x_2) =  x_1^2 + x_2^2 -2 x_1 - 2x_2 $
  \item[(ii)]  $f(x_1,x_2) =  - x_1^2 + x_1 x_2 -x_2^2 + x_1 - x_2$
  \item[(iii)] $f(x_1,x_2) = x_1^2 - 2x_1 x_2 + x_2^2$
  \end{itemize}
\end{enumerate}

\section{Matrix Algebra}

\renewcommand{\labelenumi}{\textbf{Problem \arabic{enumi}}:}
\renewcommand{\labelenumii}{(\roman{enumii})}
\begin{enumerate}
\item 
  \textit{Let
    $I = \begin{bmatrix} 1 & 0 \\ 0 & 1 \end{bmatrix}$, 
    $A = \begin{bmatrix} 1 & 2 \\ 3 & 4 \end{bmatrix}$, 
    $B = \begin{bmatrix} 0 & 1 \\ 1 & 0 \end{bmatrix}$, 
    $C = \begin{bmatrix} -2 & 0 \\ 0 & 2 \end{bmatrix}$.
    \begin{enumerate}
    \item Calculate $AB + 5I - 1C$.
    \item Show $IA = AI = A$.
    \item Show that $(AB)^T = B^T A^T$.
    \item Does $AB = BA$?
    \item $(AB)C = A(BC)$?
    \end{enumerate}} 
  Just calculations.
\item \textit{(More  difficult).   Let 
    $A = \begin{bmatrix} a_{11} &
      \cdots & a_{1N} \\
      \vdots & & \vdots \\
      a_{M1} & \cdots & a_{MN} 
    \end{bmatrix}$ 
    be an $M$ by $N$ matrix,  
    $B = \begin{bmatrix} b_{11} &
      \cdots & b_{1K} \\
      \vdots & & \vdots \\
      b_{N1} & \cdots & b_{NK} 
    \end{bmatrix}$
    be an $N$ by $K$ matrix, and 
    $C = \begin{bmatrix} c_{11} &
      \cdots & c_{1L} \\
      \vdots & & \vdots \\
      c_{K1} & \cdots & c_{KL} 
    \end{bmatrix}$ 
    be a $K$ by $L$ matrix. 
    Show that $(ABC = A(BC)$.  Hint:  Take the $ij$th element of
    $(AB)C$ (which is equal    
    to $\begin{bmatrix} \sum_{n=1}^N a_{in} b_{n1}, \sum_{n=1}^N
      a_{in} b_{n2}, cdots, \sum_{n=1}^N a_{in}
      b_{nL}\end{bmatrix} \begin{bmatrix} c_{1j} \\ \vdots c_{Kj}
    \end{bmatrix}$ and show that is equal to the $ij$th element of
    $A(BC)$. } \\  
  Following the hist, the $ij$th element of $(AB)C$ is 
  \begin{align*}
    \begin{bmatrix} \sum_{n=1}^N a_{in} b_{n1}, \sum_{n=1}^N
      a_{in} b_{n2}, cdots, \sum_{n=1}^N a_{in}
      b_{nK}\end{bmatrix} \begin{bmatrix} c_{1j} \\ \vdots c_{Kj}
    \end{bmatrix} = & \sum_{k=1^K} c_{kj} \left(\sum_{n=1}^N a_{in}
      b_{nk}\right)
  \end{align*}
  Assume that the elements of the matrix belong to a commutative ring
  (e.g. real numbers, complex numbers, rationals, integers, etc), so
  multiplication is distributive and commutative and addition is
  commutative.\footnote{It's okay if you don't know what this sentence
    means. In the context of this course, it will usually be okay to
    implicitly assume that we're dealing with real numbers.} Then, 
  \[ \sum_{k=1^K} c_{kj} \left(\sum_{n=1}^N a_{in}
    b_{nk}\right)  = \sum_{k=1^K}\sum_{n=1}^N a_{in} b_{nk} c_{kj}. \]
  By the same reasoning, the $ij$th element of $A(BC)$ is 
  \begin{align*}
    \begin{bmatrix} a_{i1} & \cdots & a_{iN} \end{bmatrix} 
    \begin{bmatrix} \sum_{k=1}^K b_{1k}c_{kj} \\ \vdots  \sum_{k=1}^K
      b_{Nk}c_{kj} \end{bmatrix} = & \sum_{n=1}^N a_{in}
    \left(\sum_{k=1}^K b_{nk}c_{kj} \right) \\
    = & \sum_{n=1}^N \sum_{k=1}^K a_{in} b_{nk} c_{kj} 
  \end{align*}
\item \textit{(Difficult)   Let }$A  = \begin{bmatrix} a_1 & b_1 \\ a_2 &
      b_2 \end{bmatrix}$.  \textit{Let} $\begin{bmatrix} a_1 \\
      a_2 \end{bmatrix}$ \textit{and } $\begin{bmatrix} b_1 \\
      b_2 \end{bmatrix}$ \textit{be points in 2 dimensional space.  Now use
    the origin and the two points to form a parallelogram. Show that
    the area of the parallelogram is equal to $|A|$ (except possibly
    for sign). Hint: the area of the parallelogram is equal to the
    base times the height.}  \\
  Probably need a picture to adequately explain the reasoning, but
  anyway, let's call the line from the origin to $b$ the base. Its
  length is $\Vert b \Vert$, where $\Vert x \Vert = \sqrt{x_1^2 +
    x_2^2}$ denotes the usual $\ell^2$ norm. The height forms a
  right-angle triangle with the line from the origin to $a$ as the
  hypotenuse and the projection of $a$ onto $b$ as the other side. The
  length of the projection of $a$ onto $b$ is $\frac{|a\dot b|}{\Vert
    b \Vert}$. Thus, the height is
  \[ h = \sqrt{ \Vert a \Vert^2 - \frac{|a\dot b|^2}{\Vert
      b \Vert^2} }, \]
  and the area of the paralellogram is
  \begin{align*}
    \Vert b \Vert h = & \sqrt{ \Vert b \Vert^2 \Vert a \Vert^2 - (a
      \dot b)^2 }
    \\
    = & \sqrt{ (b_1^2 + b_2^2)(a_1^2 + a_2^2) - (a_1 b_1 + a_2 b_2)^2
    } \\
    = & \sqrt{ (b_1^2 a_2^2 + b_2^2 a_1^2 - 2(a_1 b_1 a_2 b_2) } \\
    = & |a_1 b_2 - a_2 b_1| \\
    = & |\left( |A| \right) |.
  \end{align*} 
\item \textit{Let $A = \begin{bmatrix} a_{11} & a_{12} \\ a_{21} &
    a_{22} \end{bmatrix}$ and
  $B = \begin{bmatrix} b_{11} & b_{12} \\ b_{21} &
    b_{22} \end{bmatrix}$.  Show $|AB| = |A||B|$.} \\
  Just algebra.
\item \textit{Suppose we are given $N-1$ $N$--dimensional vectors, $A_2
    = \begin{bmatrix} a_{12} \\ \vdots a_{N2}
    \end{bmatrix}$, $cdots$, $A_{N} = \begin{bmatrix} a_{1N} \\ \vdots a_{NN}
    \end{bmatrix}$ and we define $A_1 = k_2 A_2 + ... + k_N A_N$. Show
    that $|A| = 0$ where $A = \begin{bmatrix} A_1 & A_2 & \cdots &
      A_N \end{bmatrix}$. Hint: use the definition of $A_1$
    above and the previous 4 lemmas.} \\
  By lemma 2, $|A| = |A^T|$. Repeated application of lemma 4 shows that
  \[ |A^T| = \left\vert \begin{bmatrix} k_2 A_2^T\\ A_2^T \\ \vdots \\ A_N^T
    \end{bmatrix} \right\vert + ... + \left\vert \begin{bmatrix} k_N A_N^T
      \\ A_2^T \\ \vdots \\ A_N^T 
    \end{bmatrix} \right\vert
  \]
  Lemma 3 shows that for each $j$, 
  \[  \left\vert \begin{bmatrix} k_j A_j^T \\ A_2^T \\ \vdots\\ A_N^T
    \end{bmatrix} \right\vert  =  k_j \left\vert \begin{bmatrix} A_j^T
      \\ A_2^T \\ \vdots \\ A_N^T
    \end{bmatrix} \right\vert = 0,\]. 
  where the last equality follows from lemma 1. 
\item \textit{Show that if $A$ is lower triangular, then $|A|≡ 
    \prod_{i=1}^N a_{ii} $.   Hint:  Use Lemmas (2) and (7).} \\
  Hint is the solution.
\item \textit{Calculate $|A|$ if $A$ is defined as follows:
    \begin{enumerate}
    \item $A = \begin{bmatrix}
        1 & 2 & 3 \\
        2 & 4 & 6 \\
        7 & 8 & 9 
      \end{bmatrix}$
    \item $A = \begin{bmatrix}
        0 & 0 & 0 & 1 \\
        0 & 1 & 0 & 0 \\
        0 & 0 & 2 & 0 \\
        1 & 0 & 0 & 0
      \end{bmatrix}$
    \end{enumerate}} 
\item \textit{Suppose $A = \begin{bmatrix}1 & 0 \\ 0 & 1 \end{bmatrix}$
    and 
    $B = \begin{bmatrix} 1 & 1 \\ 1 & 1 \end{bmatrix}$.  Is it true
    that $|A+B| = |A| + |B|$?} \\
  No ...
\item \textit{Calculate a right inverse for the following matrices:
  $\begin{bmatrix} 1 & 0 \\
    0 & 1 \end{bmatrix}$ ,
  $\begin{bmatrix} 
    1 & 2 \\
    3 & 4
  \end{bmatrix}$, 
  $\begin{bmatrix}
    a & b \\
    c & d
  \end{bmatrix}$,
  assuming $ad - bc \neq 0$  and 
  $\begin{bmatrix}
    1 & 0 & 0 \\
    0 & 1 & 2 \\
    0 & 3 & 4
  \end{bmatrix}$.}
\item \textit{Suppose that the $N$ by $N$ matrix $A$ has a right inverse $B$
    and a left inverse $C$.  Show that $B = C$.  Hint: You will need the
    results of problem 2.} \\
  From problem 2, $(CA)B = C(AB)$. Since $B$ is a right inverse and
  $C$ a left, this becomes $IB = CI$, so $B=C$.
\item \textit{If $A$ is an $N$ by $N$ matrix and $|A| \neq 0$, show that a
    left inverse exists.  (Note: Problem 10 assumed the existence of a left
    inverse; here we have to show that one exists.  Hint: If $|A| \neq 0$,
    then $|A^T| \neq 0$.  Thus $A^T$ will have a right inverse by lemma
    (11)).} \\
  By lemma 11, $A^T$ has a right inverse, call it $B$. We know that
  $A^T B = I$. Taking the transpose of both sides, $(A^T B)^T = I$,
  $B^T A = I$. Thus, the left inverse of $A$ exists and is equal to
  $B^T$. 
\item \textit{If $A$ is an $N$ by $N$ matrix and $|A| = 0$, show that there
    does not exist an $N$ by $N$ matrix $B$ such that $AB = I_N$.  Hint:
    You may find lemma (6) useful.} \\
  By lemma 6, $|AB| = |A||B|$, but $|I_N| = 1$, so there can be no $B$
  such that $AB = I_N$.
\item \textit{Given $Ax  =  b$  where   
  $A = \begin{bmatrix}
    1 & 0 & 0 \\
    0 & 1 & 2 \\
    0 & 3 & 4
  \end{bmatrix}$ and $b = \begin{bmatrix} 5 \\ 1 \\ 0 \end{bmatrix}$,
  calculate the solution $x^*$.} 
\item \textit{Let $A$ be a $2$ by $N$ matrix.  Find a sequence of elementary
    row operations of the form defined by (i) and (ii) above that will
    interchange the rows of $A$; i.e., transform $A = \begin{bmatrix}
      A_1 \\ A_2 \end{bmatrix}$ into $\begin{bmatrix} A_2 \\
      A_1 \end{bmatrix}$ using the two elementary row operations that we
    have defined.  Hint: four elementary row operations will be
    required.} 
\item \textit{Let $A$ by $M$ by $N$ where $M > N $ and consider the system of
  equations}
  \[
  Ax = b
  \]
  \textit{where $x$ is an $N$ dimensional solution vector and $b$ is an $M$
  dimensional vector of parameters.  Suppose the $N$ columns of $A =
  [A_1 ,A_2 ,\cdots,A_N]$ are linearly independent.  Under what
  conditions on $b$ will a solution, $x$, exist and how could you
  compute it if it did exist?  Hint: Make use of the $M$ by $M$
  elementary row matrix $E$ which reduces $A$ to upper triangular form
  $U$; i.e., $E$ and $U$ satisfy (28) and (29) in the text above.}
\item \textit{Suppose the $N$ components of the $b$ vector are all functions
    of the scalar variable $t$; i.e., we have $b(t) = [b_1(t),\cdots,
    b_N(t)]^T$.  Define }
  \[ x(t) = A^{-1} b(t), \] 
  \textit{where the $N$ by $N$ matrix $A$ does not
    depend on $t$ and $|A|\neq 0$.  Exhibit a formula for the vector of
    derivatives, $x'(t)$ .  Hint:  This problem is easy!}
\item \textit{Let $A$ be an $N$ by $N$ matrix.  Regard $|A|$ as a
    function of the $ij$th element of $A$, $a_{ij}$; i.e., define the
    function $f(a_{ij}) = |A|$.  Find a formula for the derivatives of
    the determinant of A with respect to $a_{ij}$; i.e., calculate
    $f'(a_{ij})$.  Hint: use Lemma (10).}
\end{enumerate}


\end{document}



